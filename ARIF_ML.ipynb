{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIF ML\n",
    "Ironhack certification project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Update Columns selection function if needed\n",
    "2. Go to cell RUN_ALL_ABOVE to init environement & functions\n",
    "3. Modify json params\n",
    "4. Init Log (mandatory only before first run. Result are stored in the same dataframes)\n",
    "5. Run Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic & data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime\n",
    "import json\n",
    "import os\n",
    "import dtreeviz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path=r\"fig/\"     # Relative path for image storage if option is True\n",
    "fig_path_run=r\"fig/\"\n",
    "importance_sav = pd.DataFrame(columns=['Feature','Importance','simu'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQL connexion to lcalhost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Specify connection to MySQL\n",
    "SQLengine = create_engine('mysql+mysqlconnector://anonymous:anonymous@localhost:3306/arif_dw')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_directory(dir_path):\n",
    "    # input : dir_path string : initial path\n",
    "    # output : new_directory_path string : final path with \\RUNS_YYYYMMDD_#### \n",
    "\n",
    "    # Get the current date in the format 'yyyymmdd'\n",
    "    current_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "    # Find the maximum incremented number among existing directories\n",
    "    max_number = 0\n",
    "    for item in os.listdir(dir_path):\n",
    "        if item.startswith(f\"RUNS_{current_date}_\"):\n",
    "            try:\n",
    "                number = int(item.split('_')[-1])\n",
    "                max_number = max(max_number, number)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    # Increment the max number\n",
    "    incremented_number = max_number + 1\n",
    "\n",
    "    # Create the new directory name\n",
    "    new_directory_name = f\"RUNS_{current_date}_{incremented_number:04d}\"\n",
    "\n",
    "    # Create the new directory path\n",
    "    new_directory_path = os.path.join(dir_path, new_directory_name)\n",
    "\n",
    "    # Create the directory\n",
    "    os.makedirs(new_directory_path)\n",
    "\n",
    "    return new_directory_path + '/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatset & Columns describe Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describeCol(Dataf, col, showgraph=True, min_y=0, max_y=10000, dotcolor='cyan'):\n",
    "    # Describa a column pf a dataset\n",
    "    # Input :   Dataf : Dataframe to inspect\n",
    "    #           col string : column to inspect \n",
    "    #           showgraph bool : display or not graphs for distribution\n",
    "    #           min_y, max_y int : Y axis for Boxplot praph\n",
    "    #           dotcolor color\n",
    "    # Ouput : Only display graph, used for EDA or debugging\n",
    "\n",
    "\n",
    "    if showgraph:\n",
    "        # Create the figure and axes\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "        # Left plot - Histogram\n",
    "        ax2 = axes[0].twinx()\n",
    "        sns.histplot(data=Dataf[col], ax=axes[0], kde=True)\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        ax2.set_ylabel('Kernel Density')\n",
    "        axes[0].set_title('Data distribution for \"'+ col + '\"', fontsize=12)\n",
    "        print(col)\n",
    "        \n",
    "\n",
    "        if Dataf[col].dtype != object:  # Skip non-numeric columns\n",
    "            # Right plot - Boxplot\n",
    "            sns.stripplot(data=Dataf[col], ax=axes[1], color=dotcolor, alpha=0.1)\n",
    "            sns.boxplot(data=Dataf[col], ax=axes[1], width=0.4, notch=True, zorder=10)\n",
    "            \n",
    "            axes[1].set_title('Boxplot for \"' + col + '\"', fontsize=12)\n",
    "            \n",
    "            # Set the y-axis limits for both left and right plots\n",
    "            #max_val = max(Dataf[col].max(), max_y)\n",
    "            #axes[0].set_ylim(0, max_val)\n",
    "            axes[1].set_ylim(min_y, max_y)\n",
    "\n",
    "            axes[1].yaxis.tick_right()\n",
    "            axes[1].set_xlabel(col)\n",
    "            axes[1].set_ylabel('Values')\n",
    "            axes[1].yaxis.set_label_position('right')\n",
    "        \n",
    "        # Adjust spacing between subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset describe\n",
    "def describeDataset(Dataf, showHead=5, showGraphs=True, showStats=True , fdotcolor='cyan'):\n",
    "    # Describe each columns of a dataset, count the NaN values.\n",
    "    # Input :       Dataf : Dataframe to explore\n",
    "    #               showHead int: display n first rows, use 0 for none\n",
    "    #               showGraphs bool, show distribution & boxplot graph\n",
    "    #               showStats bool, show statistics (pd.describe())\n",
    "    #               fdotcolor color\n",
    "    # Output : Only displaying graphs and stats\n",
    "\n",
    "\n",
    "    print('Describe ')\n",
    "    print('Shape:', Dataf.shape)\n",
    "    if not showHead == 0:\n",
    "        display(Dataf.head(showHead))\n",
    "\n",
    "    columns_desc = pd.DataFrame(\n",
    "        columns=['name', 'type', 'NaN', 'NaN%', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "    flagNoNaN = True\n",
    "    \n",
    "\n",
    "    for col in Dataf.columns:\n",
    "        NbNaN = 0\n",
    "        if not Dataf[col].isna().sum() == 0:\n",
    "            flagNoNaN = False\n",
    "            NbNaN += Dataf[col].isna().sum()\n",
    "            #print(col, 'NaN:', Dataf[col].isna().sum())\n",
    "        NaNp = round(NbNaN / len(Dataf) * 100)\n",
    "        \n",
    "        if Dataf[col].dtype != object:  # Skip non-numeric columns\n",
    "            describeList = Dataf[col].describe()\n",
    "            new_result = pd.DataFrame({'name': [col],\n",
    "                                       'type': [Dataf[col].dtypes],\n",
    "                                       'NaN': [NbNaN],\n",
    "                                       'NaN%': [NaNp],\n",
    "                                       'count': [describeList['count']],\n",
    "                                       'mean': [describeList['mean']],\n",
    "                                       'std': [describeList['std']],\n",
    "                                       'min': [describeList['min']],\n",
    "                                       '25%': [describeList['25%']],\n",
    "                                       '50%': [describeList['50%']],\n",
    "                                       '75%': [describeList['75%']],\n",
    "                                       'max': [describeList['max']]})\n",
    "\n",
    "            columns_desc = pd.concat([columns_desc, new_result], axis=0)\n",
    "\n",
    "            fmin_y = describeList['25%'] - 1.5 * (describeList['75%']-describeList['25%']) \n",
    "            fmax_y = describeList['75%'] + 1.9 * (describeList['75%']-describeList['25%']) \n",
    "            #print('25%',describeList['25%'])\n",
    "            #print('75%',describeList['75%'])\n",
    "            #print('IQR',describeList['75%']-describeList['25%'] )\n",
    "            #print('fmin_y',fmin_y)\n",
    "            #print('fmax_y',fmax_y)\n",
    "            if describeList['min'] <= 0:\n",
    "                 fmin_y=-10\n",
    "                 \n",
    "\n",
    "            # _w1 and _w2 are runing values, with same distribution as the original\n",
    "            fshowgraph = (col[-3:-1] != '_w') & showGraphs\n",
    "           \n",
    "            describeCol(Dataf,col,showgraph=fshowgraph,min_y=fmin_y,max_y=fmax_y,dotcolor=fdotcolor)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            new_result = pd.DataFrame({'name': [col],\n",
    "                                       'type': [str(Dataf[col].dtype)],\n",
    "                                       'NaN': [NbNaN],\n",
    "                                       'NaN%': [NaNp]})\n",
    "            columns_desc = pd.concat([columns_desc, new_result], axis=0)\n",
    "        \n",
    "    if showStats: display(columns_desc)\n",
    "\n",
    "    if flagNoNaN:\n",
    "            print('No NaN Values')\n",
    "    return columns_desc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Columns selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def selectColumns_All(Dataf):\n",
    "    # Keep only the column specified for selection \"ALL\"\n",
    "\n",
    "    Dataf= Dataf[[    #'region_name',\n",
    "                     'week' ,\n",
    "                    #'date' ,\n",
    "                    #'inc100' ,\n",
    "                    'inc100_w1' ,\n",
    "                    'inc100_w2' ,\n",
    "                    #'inc100low' ,\n",
    "                    #'inc100low_w1' ,\n",
    "                    #'inc100low_w2' ,\n",
    "                    #'inc100top' ,\n",
    "                    #'inc100top_w1' ,\n",
    "                    #'inc100top_w2' ,\n",
    "                    'C6H6' ,  #too few datas \n",
    "                    'CO' ,\n",
    "                    'NO' ,\n",
    "                    'NO2' ,\n",
    "                    'NOXasNO2' ,\n",
    "                    'O3' ,\n",
    "                    'PM10' ,\n",
    "                    'PM2p5' ,\n",
    "                    'SO2' ,\n",
    "                    'C6H6_w1' ,\n",
    "                    'CO_w1' ,\n",
    "                    'NO_w1' ,\n",
    "                    'NO2_w1' ,\n",
    "                    'NOXasNO2_w1' ,\n",
    "                    'O3_w1' ,\n",
    "                    'PM10_w1' ,\n",
    "                    'PM2p5_w1' ,\n",
    "                    'SO2_w1' ,\n",
    "                    'C6H6_w2' ,\n",
    "                    'CO_w2' ,\n",
    "                    'NO_w2' ,\n",
    "                    'NO2_w2' ,\n",
    "                    'NOXasNO2_w2' ,\n",
    "                    'O3_w2' ,\n",
    "                    'PM10_w2' ,\n",
    "                    'PM2p5_w2' ,\n",
    "                    'SO2_w2' ,\n",
    "                    'pmer' ,\n",
    "                    #'dirv' ,\n",
    "                    #'vitv' ,\n",
    "                    'temp' ,\n",
    "                    'hum' ,\n",
    "                    'pst' ,\n",
    "                    'r1' ,\n",
    "                    #'tempc' ,\n",
    "                    'pmer_w1' ,\n",
    "                    #'dirv_w1' ,\n",
    "                    #'vitv_w1' ,\n",
    "                    'temp_w1' ,\n",
    "                    'hum_w1' ,\n",
    "                    'pst_w1' ,\n",
    "                    'r1_w1' ,\n",
    "                    #'tempc_w1' ,\n",
    "                    'pmer_w2' ,\n",
    "                    #'dirv_w2' ,\n",
    "                    #'vitv_w2' ,\n",
    "                    'temp_w2' ,\n",
    "                    'hum_w2' ,\n",
    "                    'pst_w2' ,\n",
    "                    'r1_w2' ,\n",
    "                    #'tempc_w2'        \n",
    "                    ]]\n",
    "    # Set the index of the DataFrame to the 'timestamp' column\n",
    "    Dataf.set_index('week', inplace=True)\n",
    "    # Reset the index with new consecutive values\n",
    "    #Dataf.reset_index(drop=True, inplace=True)\n",
    "    return Dataf\n",
    "\n",
    "def selectColumns_Minimal(Dataf):\n",
    "    # Keep only the column specified for selection \"MIN\"\n",
    "    Dataf= Dataf[['week' ,\n",
    "                'CO_w2' ,\n",
    "                'NO_w2' ,\n",
    "                'NO2_w2' ,\n",
    "                'NOXasNO2_w2' ,\n",
    "                'O3_w2' ,\n",
    "                'PM10_w2' ,\n",
    "                'PM2p5_w2' ,\n",
    "                'SO2_w2' ,\n",
    "                'pmer_w2' ,\n",
    "                'temp_w2' ,\n",
    "                'hum_w2' ,\n",
    "                'pst_w2' ,\n",
    "                'r1_w2' ]]\n",
    "    \n",
    "    # Set the index of the DataFrame to the 'timestamp' column\n",
    "    Dataf.set_index('week', inplace=True)\n",
    "    # Reset the index with new consecutive values\n",
    "    #Dataf.reset_index(drop=True, inplace=True)\n",
    "    return Dataf\n",
    "\n",
    "def selectColumns_Selection1(Dataf):\n",
    "    # Keep only the column specified for selection \"SET1\"\n",
    "    Dataf= Dataf[[   #'region_name',\n",
    "                     'week' ,\n",
    "                    #'date' ,\n",
    "                    #'inc100' ,\n",
    "                    #'inc100_w1' ,\n",
    "                    #'inc100_w2' ,\n",
    "                    #'inc100low' ,\n",
    "                    #'inc100low_w1' ,\n",
    "                    #'inc100low_w2' ,\n",
    "                    #'inc100top' ,\n",
    "                    #'inc100top_w1' ,\n",
    "                    #'inc100top_w2' ,\n",
    "                    'C6H6' ,  #too few datas \n",
    "                    'CO' ,\n",
    "                    'NO' ,\n",
    "                    'NO2' ,\n",
    "                    #'NOXasNO2' ,\n",
    "                    'O3' ,\n",
    "                    'PM10' ,\n",
    "                    'PM2p5' ,\n",
    "                    'SO2' ,\n",
    "                    #'C6H6_w1' ,\n",
    "                    #'CO_w1' ,\n",
    "                    #'NO_w1' ,\n",
    "                    #'NO2_w1' ,\n",
    "                    #'NOXasNO2_w1' ,\n",
    "                    #'O3_w1' ,\n",
    "                    #'PM10_w1' ,\n",
    "                    #'PM2p5_w1' ,\n",
    "                    #'SO2_w1' ,\n",
    "                    #'C6H6_w2' ,\n",
    "                    #'CO_w2' ,\n",
    "                    #'NO_w2' ,\n",
    "                    #'NO2_w2' ,\n",
    "                    #'NOXasNO2_w2' ,\n",
    "                    #'O3_w2' ,\n",
    "                    #'PM10_w2' ,\n",
    "                    #'PM2p5_w2' ,\n",
    "                    #'SO2_w2' ,\n",
    "                    #'pmer' ,\n",
    "                    #'dirv' ,\n",
    "                    #'vitv' ,\n",
    "                    #'temp' ,\n",
    "                    'hum' ,\n",
    "                    #'pst' ,\n",
    "                    #'r1' ,\n",
    "                    'tempc' ,\n",
    "                    #'pmer_w1' ,\n",
    "                    #'dirv_w1' ,\n",
    "                    #'vitv_w1' ,\n",
    "                    #'temp_w1' ,\n",
    "                    #'hum_w1' ,\n",
    "                    #'pst_w1' ,\n",
    "                    #'r1_w1' ,\n",
    "                    #'tempc_w1' ,\n",
    "                    #'pmer_w2' ,\n",
    "                    #'dirv_w2' ,\n",
    "                    #'vitv_w2' ,\n",
    "                    #'temp_w2' ,\n",
    "                    #'hum_w2' ,\n",
    "                    #'pst_w2' ,\n",
    "                    #'r1_w2' ,\n",
    "                    #'tempc_w2'        \n",
    "                    ]]\n",
    "        # Set the index of the DataFrame to the 'timestamp' column\n",
    "    Dataf.set_index('week', inplace=True)\n",
    "    # Reset the index with new consecutive values\n",
    "    #Dataf.reset_index(drop=True, inplace=True)\n",
    "    return Dataf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FillXy(dataFram, selection='SET1', verbose=True):\n",
    "        # Define X,y with the selection ALL MIN or SET1 columns\n",
    "        # Input:        dataFram : Dataframe source to use\n",
    "        #               selection = 'ALL', 'MIN', 'SET1'\n",
    "        #               verbose bool: display debugging dialog\n",
    "        # Output : X,y : Dataframes with selected columns\n",
    "        \n",
    "        if selection =='ALL':\n",
    "                fX = selectColumns_All(dataFram)\n",
    "        elif selection == 'MIN':\n",
    "                fX = selectColumns_Minimal(dataFram)\n",
    "        elif selection == 'SET1':\n",
    "                fX = selectColumns_Selection1(dataFram)\n",
    "        else:\n",
    "                fX = selectColumns_Minimal(dataFram)\n",
    "\n",
    "\n",
    "        fy = dataFram['inc100'].copy()\n",
    "        FeaturesCount = len(fX.columns)\n",
    "        params['col_sel'] = selection\n",
    "        selected_cols = fX.columns\n",
    "        params['col_0'] = FeaturesCount\n",
    "        params['X_len'] = len(fX)\n",
    "        \n",
    "        fX.reset_index(drop=True, inplace=True)\n",
    "        fy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        if verbose:\n",
    "                print('FillXy: ',selection)\n",
    "                print('X:',fX.shape)\n",
    "                print('y:',fy.shape)\n",
    "                print('FeaturesCount',FeaturesCount)\n",
    "                print('FillXyDone')\n",
    "        return fX, fy\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove Outliers, imputes function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove Outliers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeOutliers(Dataf, cursor=1.5,  verbose=True):\n",
    "    # Remove values above a threeshold on distribution for all columns in a dataframe, replace by NaN\n",
    "    # Minimum : (Q1 - cursor * IQR)   Maximum : (Q3 + cursor * IQR)  see boxplot\n",
    "    # Input:    Dataf : Dataframe\n",
    "    #           cursor=1.5 float\n",
    "    # Output:   dataframe\n",
    "\n",
    "\n",
    "    Datafc = Dataf.copy()\n",
    "    for col in Dataf:\n",
    "        \n",
    "        if verbose: print('col:',col)\n",
    "        if Datafc[col].dtype != object:  # Skip non-numeric columns\n",
    "            describeList = Dataf[col].describe()\n",
    "            max = describeList['75%']+(cursor*(describeList['75%']-describeList['25%']))\n",
    "            min = describeList['25%']-(cursor*(describeList['75%']-describeList['25%']))\n",
    "            if verbose: print('NaN:',Datafc[col].isnull().sum(),'min:', min, '25%:',describeList['25%'],'75%:',describeList['75%'],'max:',max)\n",
    "            #affect NaN to outliers\n",
    "            Datafc.loc[Datafc[col] < min,col] = np.nan\n",
    "            Datafc.loc[Datafc[col] > max,col] = np.nan\n",
    "            if verbose: print('NaN',Datafc[col].isnull().sum())\n",
    "        else:\n",
    "            if verbose: print('Non-numeric col:',col)\n",
    "    \n",
    "    return Datafc\n",
    "\n",
    "def assign_nan_to_values_above_threshold(dataframe, columns, threshold):\n",
    "    for column_name in columns:\n",
    "        if column_name in dataframe.columns:\n",
    "            values_below_threshold = dataframe.loc[dataframe[column_name] < threshold, column_name]\n",
    "            mean_below_threshold = values_below_threshold.mean()\n",
    "            dataframe.loc[dataframe[column_name] > threshold, column_name] = mean_below_threshold\n",
    "       \n",
    "    return dataframe\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute by mean or median function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeByMeanMedian(Dataf, cols, median=False, imputeNaN=True, impute_zeros=True, verbose=True, use_neighbors=False, neighbors=4):\n",
    "    # imputeByMean Using mean or median to impute the missing values\n",
    "    # Input :   Dataf : Dataframe\n",
    "    #           cols : List of string with columns nale to inpute\n",
    "    #           median bool : Use median, else use mean\n",
    "    #           imputeNaN bool, inpute NaN\n",
    "    #           impute_zeros bool, inpute zero\n",
    "    #           use_neighbors bool: for time series, use neighbors mean or median \n",
    "    #           neighbors int : how many neighbors to use\n",
    "    # OutPut :  dataframe\n",
    "\n",
    "\n",
    "\n",
    "    Dataf = Dataf.copy()\n",
    "    Dataf.reset_index(drop=True, inplace=True)  # Reset index\n",
    "\n",
    "    for col in cols:\n",
    "        if imputeNaN:\n",
    "            if median:\n",
    "                Dataf[col] = Dataf[col].fillna(Dataf[col].median())\n",
    "            else:\n",
    "                Dataf[col] = Dataf[col].fillna(Dataf[col].mean())\n",
    "        if impute_zeros:\n",
    "            if median:\n",
    "                Dataf.loc[Dataf[col] == 0, col] = Dataf.loc[Dataf[col] == 0, col].fillna(Dataf[Dataf[col] == 0][col].median())\n",
    "            else:\n",
    "                Dataf.loc[Dataf[col] == 0, col] = Dataf.loc[Dataf[col] == 0, col].fillna(Dataf[Dataf[col] == 0][col].mean())\n",
    "        if use_neighbors:\n",
    "            Dataf[col] = Dataf[col].fillna(Dataf[col].where(Dataf[col].notnull(), Dataf[col].rolling(neighbors, min_periods=1, center=True).mean()))\n",
    "    \n",
    "\n",
    "    Dataf.set_index(Dataf.index, inplace=True)  # Set index back to the original\n",
    "    \n",
    "    return Dataf\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN imputation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def imputeByKNN(Dataf,imputeNaN=True, impute_zeros=True, verbose=True):\n",
    "    #KNN imputation algorithm\n",
    "    # Input :   Dataf : Dataframe\n",
    "    #           imputeNaN bool, inpute NaN\n",
    "    #           impute_zeros bool, inpute zero\n",
    "    # OutPut :  dataframe\n",
    "\n",
    "    Dataf = Dataf.copy()\n",
    "    if imputeNaN:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        imputed_data = imputer.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data, columns=Dataf.columns)\n",
    "    if impute_zeros:\n",
    "        imputer = KNNImputer(n_neighbors=5,missing_values=0)\n",
    "        imputed_data = imputer.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data, columns=Dataf.columns)        \n",
    "\n",
    "    params['impute']='KNNImputer'\n",
    "    return Dataf\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleImputer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def imputeBySimpleImputer(Dataf, strategy='mean',imputeNaN=True, impute_zeros=True, verbose=True):\n",
    "    #SimpleImputer\n",
    "    # Input :   Dataf : Dataframe\n",
    "    #           strategy : 'mean', 'median'\n",
    "    #           imputeNaN bool, inpute NaN\n",
    "    #           impute_zeros bool, inpute zero\n",
    "    # OutPut :  dataframe\n",
    "\n",
    "    Dataf = Dataf.copy()\n",
    "    if imputeNaN:\n",
    "        imputer = SimpleImputer(strategy=strategy)\n",
    "        imputed_data = imputer.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data, columns=Dataf.columns)\n",
    "    if impute_zeros:\n",
    "        imputer = SimpleImputer(strategy=strategy,missing_values=0)\n",
    "        imputed_data = imputer.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data, columns=Dataf.columns)      \n",
    "\n",
    "    params['impute']= 'SimpleImputer'   \n",
    "    return Dataf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate feature imputation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "def imputeByIterativeImputer(Dataf, imputeNaN=True, impute_zeros=True, verbose=True):\n",
    "    # Input :   Dataf : Dataframe\n",
    "    #           imputeNaN bool, inpute NaN\n",
    "    #           impute_zeros bool, inpute zero\n",
    "    # OutPut :  dataframe\n",
    "    \n",
    "    Dataf = Dataf.copy()\n",
    "\n",
    "    if imputeNaN:\n",
    "        imputer = IterativeImputer()\n",
    "        imputed_data = imputer.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data, columns=Dataf.columns)\n",
    "\n",
    "    if impute_zeros:\n",
    "        imputer_zeros = IterativeImputer(missing_values=0)\n",
    "        imputed_data_zeros = imputer_zeros.fit_transform(Dataf)\n",
    "        Dataf = pd.DataFrame(imputed_data_zeros, columns=Dataf.columns)\n",
    "\n",
    "    params['impute']= 'IterativeImputer'\n",
    "    return Dataf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeData(l_Dataf,method='KNN', l_imputeNaN=True, l_impute_zeros=True, l_verbose=True):\n",
    "    # Function used to call all above inpute function\n",
    "    # Input :   l_Dataf : Dataframe\n",
    "    #           method : \"None\", \"TIME\", \"MEAN\", \"MEDIAN\", \"KNN\", \"SIM\", \"ITI\"\n",
    "    #           l_imputeNaN bool, inpute NaN\n",
    "    #           l_impute_zeros bool, inpute zero\n",
    "    # OutPut :  dataframe\n",
    "\n",
    "    if method=='MEAN':\n",
    "        l_Dataf = imputeByMeanMedian(l_Dataf,l_Dataf.columns,median=False,imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,use_neighbors=False ,verbose=l_verbose )\n",
    "        params['impute']='MEAN'\n",
    "    elif method=='MEDIAN':\n",
    "        l_Dataf = imputeByMeanMedian(l_Dataf,l_Dataf.columns,median=True,imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,use_neighbors=False ,verbose=l_verbose )\n",
    "        params['impute']='MEDIAN'\n",
    "    elif method=='TIME':\n",
    "        l_Dataf = imputeByMeanMedian(l_Dataf,l_Dataf.columns,median=False,imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,use_neighbors=True ,neighbors=4 ,verbose=l_verbose )\n",
    "        params['impute']='TIME'    \n",
    "    elif method=='KNN':\n",
    "        l_Dataf = imputeByKNN(l_Dataf,imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,verbose=l_verbose )\n",
    "    elif method=='SIM':\n",
    "        l_Dataf = imputeBySimpleImputer(l_Dataf,strategy='mean', imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,verbose=l_verbose )\n",
    "    elif method=='ITI':\n",
    "        l_Dataf = imputeByIterativeImputer(l_Dataf, imputeNaN=l_imputeNaN ,impute_zeros=l_impute_zeros ,verbose=l_verbose )\n",
    "    #elif method=='TIME':   todo\n",
    "    else:\n",
    "        params['impute']= 'none'\n",
    "    return l_Dataf\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "\n",
    "def split_data(X, y, split_method='TIME', test_size=0.2, n_splits=5, random_state=0,param_name='split', verbose=True):\n",
    "    # Split function for ML\n",
    "    # Input :   X,y : dataframes\n",
    "    #           split_method :  \"None\", \"RANDOM\", \"TIME\"\n",
    "    #           test_size float <1 : test size param for train_test_split\n",
    "    #           n_splits : n split for TimeSeriesSplit\n",
    "    #           random_state int: specify a random state, 0 correspond to none\n",
    "    #           param_name string : used for results log\n",
    "\n",
    "    if split_method == 'TIME':\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(X), start=1):\n",
    "            if i == n_splits:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                break\n",
    "        \n",
    "    elif split_method == 'RANDOM':\n",
    "        if random_state == 0:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    #This is used as a 'do nothing method' for test purpose with full set. Not valid for proessors, \n",
    "    elif split_method == 'None':\n",
    "        X_train = X\n",
    "        X_test = []\n",
    "        y_train = y\n",
    "        y_test = []\n",
    "\n",
    "    params[param_name]= split_method\n",
    "    params['x_trn']=len(X_train)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Split :',split_method)\n",
    "        print('X_train.shape',X_train.shape)\n",
    "        print('X_test.shape',X_test.shape)\n",
    "        print('y_train.shape',y_train.shape)\n",
    "        print('y_test.shape',y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "def scaleData(fX_train, verbose=True):   \n",
    "    # Scale all values of a dataframe using StandardScaler\n",
    "\n",
    "    scaler = StandardScaler().fit(fX_train)\n",
    "    fX_train_scaled = pd.DataFrame(scaler.transform(fX_train),columns=fX_train.columns)\n",
    "   # fX_test_scaled = pd.DataFrame(scaler.transform(fX_test),columns=X.columns)\n",
    "    \n",
    "    #y_train = y_train.reset_index(drop=True) \n",
    "    #y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    if verbose:\n",
    "        print('ScaleData : StandardScaler')\n",
    "        print('X_train_scaled',fX_train_scaled.shape)\n",
    "       # print('X_test_scaled',fX_test_scaled.shape)\n",
    "\n",
    "    params['scaler']='StandardScaler'\n",
    "    return fX_train_scaled #, fX_test_scaled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scaleData01(fX_train, fX_test, verbose=True):\n",
    "    # Scale all values of a dataframe using StandardScaler and MinMaxScaler with value between 0 and 1\n",
    "    scaler = StandardScaler().fit(fX_train)\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    fX_train_scaled = pd.DataFrame(scaler.transform(fX_train),columns=fX_train.columns)\n",
    "    fX_train_scaled01 = pd.DataFrame(min_max_scaler.fit_transform(fX_train_scaled),columns=fX_train.columns)\n",
    "\n",
    "    fX_test_scaled = pd.DataFrame(scaler.transform(fX_test),columns=fX_test.columns)\n",
    "    fX_test_scaled01 = pd.DataFrame(min_max_scaler.fit_transform(fX_test_scaled),columns=fX_test.columns)\n",
    "\n",
    "    #y_train = y_train.reset_index(drop=True) \n",
    "    #y_test = y_test.reset_index(drop=True)\n",
    "    if verbose:\n",
    "        print('scaleData : StandardScaler + MinMaxScaler')\n",
    "        print('X_test_scaled',fX_test_scaled.shape)\n",
    "        print('X_test_scaled01',fX_test_scaled01.shape)\n",
    "    params['scaler']='StandardScaler,MinMaxScaler01'\n",
    "    return fX_train_scaled01 , fX_test_scaled01\n",
    "\n",
    "def scale01(fX_train, verbose=True):\n",
    "\n",
    "    scaler = StandardScaler().fit(fX_train)\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    fX_train_scaled = pd.DataFrame(scaler.transform(fX_train),columns=fX_train.columns)\n",
    "    fX_train_scaled01 = pd.DataFrame(min_max_scaler.fit_transform(fX_train_scaled),columns=fX_train.columns)\n",
    "\n",
    "\n",
    "    #y_train = y_train.reset_index(drop=True) \n",
    "    #y_test = y_test.reset_index(drop=True)\n",
    "    if verbose:\n",
    "        print('scaleData : StandardScaler + MinMaxScaler')\n",
    "        print('X_train_scaled',fX_train_scaled.shape)\n",
    "        print('X_train_scaled01',fX_train_scaled01.shape)\n",
    "    params['scaler']='StandardScaler,MinMaxScaler01'\n",
    "    return fX_train_scaled01\n",
    "\n",
    "#print('y_train %1:', int(y_train.value_counts()[1]/len(y_train)*100))\n",
    "#print('y_test %1:', int(y_test.value_counts()[1]/len(y_test)*100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def selectFByCorrelation : Feature selection using correlation matrix : FS Corr>0.85:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFByCorrelation(fX,seuil,verbose=True):\n",
    "    # Feature selection using correlation matrix\n",
    "    # Input:    fX : dataframe\n",
    "    #           seuil float <1 : treeshold for correlation 0.5 - 0.95\n",
    "    # Output : dataframe\n",
    "\n",
    "    # # Create correlation matrix\n",
    "    corr_matrix = fX.corr().abs()\n",
    "    # # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # # Find features with correlation greater than 0.85\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > seuil)]\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print('selectFByCorrelation with >',seuil)\n",
    "        print(f\"Columns to drop: {to_drop}\")\n",
    "        print(f\"Number of columns to drop; {len(to_drop)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # # Drop features\n",
    "    fX.drop(to_drop, axis=1, inplace=True)\n",
    "    FeaturesCount = len(fX.columns)\n",
    "    \n",
    "    if verbose: print('New Number of columns :',FeaturesCount)\n",
    "    params['features'] ='corr=' + str(seuil)\n",
    "    params['col_1']=FeaturesCount\n",
    "    params['RFECVmts']=0\n",
    "    selected_cols=fX.columns\n",
    "    return fX\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def selectFByRFECV_LR : Feature selection using RFECV + LR \n",
    "(Recursive feature elimination with cross-validation to select feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def selectFByRFECV_LR(fX,fy, minFeaturesToSelect=1,scoRing='r2', verbose=True, graph=True,num_sim=100,lsavFig=True):\n",
    "    # Feature selection using Recursive feature elimination with cross-validation to select features unsing linear regression\n",
    "    # Input:    fX,fy : dataframe\n",
    "    #           minFeaturesToSelect int\n",
    "    #           scoRing : score to use with LR\n",
    "    #           graph bool, make graph and save as fig\n",
    "    #           num_sim int:simu number \n",
    "    #           lsavFig : not used\n",
    "    # Output : dataframe\n",
    "    \n",
    "    \n",
    "    fX = fX.fillna(0).copy()\n",
    "    # Create an instance of LinearRegression as the underlying estimator\n",
    "    #LR_params = {'C': 1,'penalty' : 'none', 'solver' : 'lbfgs'}\n",
    "    \n",
    "    LR_estimator = LinearRegression( n_jobs=-1)\n",
    "    if verbose:\n",
    "        print('select features using  RFECV LinearRegression')\n",
    "        print('RFECV estimator:',LR_estimator.__class__.__name__)\n",
    "        #print('Params :',LR_params)\n",
    "\n",
    "    # Create the RFECV object with the custom importance getter\n",
    "        print('minFeaturesToSelect',minFeaturesToSelect)\n",
    "    RFECV_LR = RFECV(estimator=LR_estimator,min_features_to_select=minFeaturesToSelect, step=1, cv=5, scoring=scoRing, n_jobs=-1,verbose=False)\n",
    "\n",
    "    # Fit RFECV on the training data  X_train, y_train\n",
    "    RFECV_LR.fit(fX, fy)\n",
    "\n",
    "    # Get the selected feature indices, column, aply to X_train\n",
    "    selected_indices = RFECV_LR.support_\n",
    "    selected_columns = fX.columns[selected_indices]\n",
    "\n",
    "    fX_selected = fX[selected_columns].copy()\n",
    "\n",
    "    selected_cols = selected_columns\n",
    "    FeaturesCount = len(selected_columns)\n",
    "    best_score_index = np.argmax(RFECV_LR.cv_results_['mean_test_score'])\n",
    "    \n",
    "    params_list = { 'minFeaturesToSelect' : minFeaturesToSelect,\n",
    "                  'scoring' : scoRing }\n",
    "    if verbose:\n",
    "        print('selected_columns:',FeaturesCount)\n",
    "        print(selected_columns)\n",
    "        \n",
    "        print('Best score',RFECV_LR.cv_results_['mean_test_score'][best_score_index])\n",
    "        #display(fX_selected.head())\n",
    "\n",
    "    # Draw a graph\n",
    "    if graph:\n",
    "        n_scores = len(RFECV_LR.cv_results_[\"mean_test_score\"])\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.xlabel(\"Number of features selected \" + str(FeaturesCount))\n",
    "        plt.ylabel(\"Mean test accuracy \" + str(round(RFECV_LR.cv_results_['mean_test_score'][best_score_index],4)) )\n",
    "        plt.errorbar(\n",
    "            range(minFeaturesToSelect, n_scores + minFeaturesToSelect),\n",
    "            RFECV_LR.cv_results_[\"mean_test_score\"],\n",
    "            yerr=RFECV_LR.cv_results_[\"std_test_score\"],\n",
    "        )\n",
    "        plt.title(\"RFECV LR\" + str(params_list))\n",
    "        plt.gca().invert_xaxis()\n",
    "        #if lsavFig:\n",
    "        plt.savefig(fig_path_run + 'RFECV_LR_' + str(num_sim).zfill(4) + '.png')\n",
    "        #else:    \n",
    "        #    plt.show()\n",
    "\n",
    "        #display(RFECV_LR.cv_results_)\n",
    "    \n",
    "    params['features'] ='RFECV(LinearRegression)'\n",
    "    params['col_1']=FeaturesCount\n",
    "    params['RFECVmts'] = str(round(RFECV_LR.cv_results_['mean_test_score'][best_score_index],4))\n",
    "    return fX_selected\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def selectFByRFECV_GB : Feature selection using RFECV + GBR \n",
    "(Recursive feature elimination with cross-validation on GradientBoostingRegressor to select feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def selectFByRFECV_GB(fX, fy, param_grid,minFeaturesToSelect=1, scoRing='r2', verbose=True, graph=True,num_sim=100,lsavFig=True):\n",
    "    # Feature selection using Recursive feature elimination with cross-validation to select features using GB regression\n",
    "    # Input:    fX,fy : dataframe\n",
    "    #           param_grid : GB parameters \n",
    "    #           minFeaturesToSelect int\n",
    "    #           scoRing : score to use with LR\n",
    "    #           graph bool, make graph and save as fig\n",
    "    #           num_sim int:simu number \n",
    "    #           lsavFig : not used\n",
    "    # Output : dataframe\n",
    "    \n",
    "    fX = fX.fillna(0).copy()\n",
    "    # Create an instance of GradientBoostingRegressor as the underlying estimator\n",
    "    \n",
    "\n",
    "\n",
    "    GB_estimator = GradientBoostingRegressor(loss=param_grid['loss'], max_depth=param_grid['max_depth'],n_estimators=param_grid['n_estimators'])\n",
    "    \n",
    "    if verbose:\n",
    "        print('select features using  RFECV GradientBoostingRegressor')\n",
    "        print('RFECV estimator:', GB_estimator.__class__.__name__)\n",
    "        print('RFECV params:', param_grid)\n",
    "\n",
    "\n",
    "    # Create the RFECV object with the custom importance getter\n",
    "    RFECV_GB = RFECV(estimator=GB_estimator, min_features_to_select=minFeaturesToSelect, step=1, cv=5, scoring=scoRing, n_jobs=-1, verbose=False)\n",
    "    \n",
    "    # Fit RFECV on the training data X_train, y_train\n",
    "    RFECV_GB.fit(fX, fy)\n",
    "    \n",
    "    # Get the selected feature indices and columns\n",
    "    selected_indices = RFECV_GB.support_\n",
    "    selected_columns = fX.columns[selected_indices]\n",
    "    \n",
    "    fX_selected = fX[selected_columns].copy()\n",
    "    \n",
    "    FeaturesCount = len(selected_columns)\n",
    "    best_score_index = np.argmax(RFECV_GB.cv_results_['mean_test_score'])\n",
    "    \n",
    "    params_list = {'minFeaturesToSelect': minFeaturesToSelect, 'scoring': scoRing}\n",
    "    \n",
    "    if verbose:\n",
    "        print('selected_columns:', FeaturesCount)\n",
    "        print(selected_columns)\n",
    "        print('Best score', RFECV_GB.cv_results_['mean_test_score'][best_score_index])\n",
    "    \n",
    "    # Draw a graph\n",
    "    if graph:\n",
    "        n_scores = len(RFECV_GB.cv_results_[\"mean_test_score\"])\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.xlabel(\"Number of features selected \" + str(FeaturesCount))\n",
    "        plt.ylabel(\"Mean test accuracy \" + str(round(RFECV_GB.cv_results_['mean_test_score'][best_score_index], 4)))\n",
    "        plt.errorbar(range(minFeaturesToSelect, n_scores + minFeaturesToSelect),\n",
    "                     RFECV_GB.cv_results_[\"mean_test_score\"],\n",
    "                     yerr=RFECV_GB.cv_results_[\"std_test_score\"])\n",
    "        plt.title(\"RFECV GBR\" + str(params_list))\n",
    "        plt.gca().invert_xaxis()\n",
    "        #if lsavFig:\n",
    "        plt.savefig(fig_path_run + 'RFECV_GBR_' + str(num_sim).zfill(4) + '.png')\n",
    "        #else:    \n",
    "           # plt.show()\n",
    "    \n",
    "    params['RFECVmts'] = str(round(RFECV_GB.cv_results_['mean_test_score'][best_score_index], 4))\n",
    "    params['features'] = 'RFECV(GradientBoostingRegressor)'\n",
    "    params['col_1'] = FeaturesCount\n",
    "    \n",
    "    return fX_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(lX,ly,lparam_grid,method='RFECV_LR',lseuil=0.85,lminFeaturesToSelect=1,lscoRing='r2', lgraph=True, lverbose=True,num_sim=100,Lsavfig=True):\n",
    "    # Features selection function\n",
    "    # Input :   lX,ly : dataframes\n",
    "    #           lparam_grid : GB parameters\n",
    "    #           method : \"None\", \"CORR\", \"RFECV_LR\", \"RFECV_GB\"\n",
    "    #           lseuil float <1 : treeshold for correlation 0.5 - 0.95\n",
    "    #           lminFeaturesToSelect int\n",
    "    #           lscoRing : score to use with LR\n",
    "    #           lgraph bool, make graph and save as fig\n",
    "    #           num_sim int:simu number \n",
    "    #           lsavFig : not used\n",
    "    # Output : dataframe          \n",
    "\n",
    "    if method=='CORR':\n",
    "        lX = selectFByCorrelation(lX,lseuil,verbose=lverbose)\n",
    "    elif method=='RFECV_LR':\n",
    "        lX = selectFByRFECV_LR(lX,ly, minFeaturesToSelect=lminFeaturesToSelect,scoRing=lscoRing, verbose=lverbose, graph=lgraph,num_sim=num_sim, lsavFig=Lsavfig)\n",
    "    elif method=='RFECV_GB':\n",
    "        lX = selectFByRFECV_GB(lX,ly,param_grid=lparam_grid, minFeaturesToSelect=lminFeaturesToSelect,scoRing=lscoRing, verbose=lverbose, graph=lgraph,num_sim=num_sim,lsavFig=Lsavfig)\n",
    "    return lX\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def testModel(t_model, X_test, y_test, df_errors ,regPlot=True,histplot=True, barPlot=True, head_test=True, tree_viz=True, verbose=True,num_sim=100,lsavFig=True):\n",
    "    # function to evaluate a model using test data\n",
    "    # input :   t_model : ML model\n",
    "    #           X_test, y_test : dataframes to test\n",
    "    #           df_errors : errors dataframe\n",
    "    #           regPlot bool :  regression graph\n",
    "    #           histplot bool : histogram with error distribution\n",
    "    #           barPlot bool : bar graph for features importances\n",
    "    #           head_test bool : add errors to df_errors\n",
    "    #           tree_viz bool : tree vizualisation for tree regression\n",
    "    #           num_sim int:simu number \n",
    "    #           lsavFig : not used\n",
    "    # Output : dataframe with biggest errors added\n",
    "\n",
    "    # Make prediction\n",
    "    \n",
    "    y_pred = t_model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # Mean absolute percentage error\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    # Calculate R-squared\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # intercept  : not available for GB\n",
    "    #intercept= t_model.intercept_\n",
    "    params['SIMU']=num_sim\n",
    "    params['mape']=mape\n",
    "    params['mse']=mse\n",
    "    params['r2']=r2\n",
    "    #params['int']=intercept\n",
    "    if verbose:\n",
    "        print(\"Mean absolute percentage error\", round(mape,2))\n",
    "        print(\"Mean Squared Error:\", round(mse,2))\n",
    "        print(\"R-squared:\", round(r2,4))\n",
    "        # lower MSE (0) indicates better accuracy in terms of the predicted values\n",
    "        # higher R-squared ( 0 to 1) value indicates a better fit of the model to the data.\n",
    "        # Print the coefficients and intercept\n",
    "        #print(\"Coefficients:\", LR_model.coef_.round(6))\n",
    "        #print(\"Intercept:\", round(intercept,2))\n",
    "\n",
    "\n",
    "\n",
    "    if regPlot:\n",
    "        # Plot the actual values and predicted values\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "        #left plot\n",
    "        sns.regplot(x=y_test,y=y_pred,fit_reg=True,ax=axes[0], scatter_kws={'alpha': 0.5})\n",
    "        sns.lineplot(x=[10,300], y=[10, 300], color='red', linestyle='--',ax=axes[0])\n",
    "        axes[0].set_xlabel('Actual')\n",
    "        axes[0].set_ylabel('Predicted')\n",
    "        axes[0].set_title('Actual vs. Predicted: ' + params['gcv_model'] + '\\n' + params['bestparam'] + '\\nMAPE:' +str(round(mape,4)))\n",
    "        axes[0].axis('equal')\n",
    "        max_value = max(y_test.max(), y_pred.max())\n",
    "        axes[0].axis([0, 300, 0, 300])\n",
    "        #plt.legend()\n",
    "\n",
    "        #right plot\n",
    "        sns.regplot(x=y_test,y=y_pred,fit_reg=True,ax=axes[1], scatter_kws={'alpha': 0.5})\n",
    "        sns.lineplot(x=[10,y_pred.max()], y=[10, y_pred.max()], color='red', linestyle='--',ax=axes[1])\n",
    "        #axes[1].set_xlabel('Actual')\n",
    "        #axes[1].set_ylabel('Predicted')\n",
    "        #axes[1].set_title('Actual vs. Predicted')\n",
    "        axes[1].axis('equal')\n",
    "        max_value = max(y_test.max(), y_pred.max())\n",
    "        axes[1].axis([0, max_value, 0, max_value])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        #if lsavFig:\n",
    "        plt.savefig(fig_path_run + 'PLOT_' + str(num_sim).zfill(4) + '.png')\n",
    "        #else:    \n",
    "        #    plt.show()\n",
    "\n",
    "\n",
    "    if histplot:\n",
    "        errors = abs((y_test - y_pred) / y_test * 100)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        # Plot the distribution of errors using Seaborn\n",
    "        sns.histplot(errors, kde=True)\n",
    "        \n",
    "\n",
    "        plt.xlabel(\"Errors\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        ax2 = plt.gca().twinx()\n",
    "        ax2.set_ylabel('Kernel Density')\n",
    "        plt.title('Errors Distribution for ' + params['gcv_model'] + '\\n' + params['bestparam'] + '\\nMAPE:' +str(round(mape,4)))\n",
    "        #plt.show()\n",
    "                \n",
    "        #if lsavFig:\n",
    "        plt.savefig(fig_path_run + 'ERR_DISTR_' + str(num_sim).zfill(4) + '.png')\n",
    "        #else:    \n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    if barPlot:\n",
    "        \n",
    "        plt.figure(figsize=(9, 4))\n",
    "        \n",
    "        # Obtain the coefficients and feature names\n",
    "        coefficients = t_model.feature_importances_\n",
    "        feature_names = t_model.feature_names_in_\n",
    "        \n",
    "        cmap = plt.get_cmap('brg')\n",
    "        # Normalize the coefficient values to range between 0 and 1\n",
    "        norm_values = (coefficients - np.min(coefficients)) / (np.max(coefficients) - np.min(coefficients))\n",
    "        colors = cmap(norm_values)\n",
    "        \n",
    "        plt.bar(range(len(coefficients)), coefficients, color=colors)\n",
    "        plt.xticks(range(len(coefficients)), feature_names, rotation=90)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Coefficient Values')\n",
    "        plt.title('Linear Regression Coefficients ' + params['gcv_model'] + '\\n' + params['bestparam'])\n",
    "        \n",
    "        plt.savefig(fig_path_run + 'LR_COEF_' + str(num_sim).zfill(4) + '.png')\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    if head_test:\n",
    "        predictions_df = pd.DataFrame(y_test)\n",
    "        #predictions_df.reset_index(drop=True)\n",
    "        predictions_df['SIMU'] = params['SIMU']\n",
    "        predictions_df['mape'] = params['mape']\n",
    "        predictions_df['Prediction'] = y_pred.round(2)\n",
    "        predictions_df['Error'] = round((y_pred-y_test)/y_test*100,2)\n",
    "        predictions_df['Input']=   X_test.round(2).to_dict(orient='records')\n",
    "        predictions_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #dislay head\n",
    "        predictions_df = predictions_df.head(10).sort_values('Error',ascending=False).copy()\n",
    "        predictions_df['Rank'] = predictions_df.index + 1\n",
    "        df_errors = pd.concat([df_errors, predictions_df], ignore_index=True)\n",
    "    return df_errors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVLR(X_train,y_train,param_grid, scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for LinearRegression\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    #param_grid = {\n",
    "    #    'fit_intercept': [True, False]}   #[True, False]\n",
    "    # Create the LinearRegression model\n",
    "    LR_model = LinearRegression()\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(LR_model, param_grid, scoring=scorer, n_jobs=-1,verbose=verbose)\n",
    "\n",
    "    \n",
    "    if verbose: print('GridSearchCV LinearRegression')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    \n",
    "    params['gcv_model']= 'LinearRegression'\n",
    "    params['n_test']= len(grid_search.cv_results_['params'])\n",
    "    params['bestparam']= str(grid_search.best_params_)\n",
    "    params['bestscore'] = round(grid_search.best_score_,4)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time']=round(elapsed_time,4)\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVGB(X_train, y_train,param_grid, scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for GradientBoostingRegressor\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    #param_grid = {\n",
    "    #    'loss': ['ls','absolute_error'],  #['ls', 'absolute_error']\n",
    "    #    'n_estimators': [50, 100, 200, 300, 400],   #[100, 200, 300, 400]\n",
    "    #    'max_depth': [5,7,9,11,15]    #[3, 4, 5, 7]\n",
    "    #}\n",
    "\n",
    "    # Create the GradientBoostingRegressor model\n",
    "    GB_model = GradientBoostingRegressor()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(GB_model, param_grid, scoring=scorer,verbose=verbose, n_jobs=-1)\n",
    "\n",
    "    if verbose: print('GridSearchCV GradientBoostingRegressor')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    params['gcv_model'] = 'GradientBoostingRegressor'\n",
    "    params['n_test']= len(grid_search.cv_results_['params'])\n",
    "    params['bestparam'] = str(grid_search.best_params_)\n",
    "    params['bestscore'] = grid_search.best_score_\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time'] = elapsed_time\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNNregressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVKNR(X_train, y_train,param_grid, scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for KNeighborsRegressor\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    #param_grid = {\n",
    "    #    'n_neighbors': [2,3,5,7,9],   #[3, 5, 7]\n",
    "    #    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  #['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    #}\n",
    "\n",
    "    # Create the NearestNeighbors model\n",
    "    NN_model = KNeighborsRegressor()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(NN_model, param_grid, scoring=scorer, n_jobs=-1, verbose=True)\n",
    "\n",
    "    if verbose: print('GridSearchCV KNeighborsRegressor')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    params['gcv_model'] = 'KNeighborsRegressor'\n",
    "    params['n_test'] = len(grid_search.cv_results_['params'])\n",
    "    params['bestparam'] = str(grid_search.best_params_)\n",
    "    params['bestscore'] = grid_search.best_score_\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time'] = elapsed_time\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVRF(X_train, y_train,param_grid,scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for RandomForestRegressor\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    #param_grid = {\n",
    "    #    'n_estimators': [100, 200, 300],   #[100, 200, 300, 400],\n",
    "    #    'max_depth': [3, 5, 7, 9]          #[3, 4, 5, 7]\n",
    "    #}\n",
    "\n",
    "    # Create the RandomForestRegressor model\n",
    "    RF_model = RandomForestRegressor()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(RF_model, param_grid, scoring=scorer,verbose=verbose, n_jobs=-1)\n",
    "\n",
    "    if verbose: print('GridSearchCV RandomForestRegressor')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    params['gcv_model'] = 'RandomForestRegressor'\n",
    "    params['n_test'] = len(grid_search.cv_results_['params'])\n",
    "    params['bestparam'] = str(grid_search.best_params_)\n",
    "    params['bestscore'] = grid_search.best_score_\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time'] = elapsed_time\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "# feature importance ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportance(model, feature_names,num_sim):\n",
    "    # Get feature importance from the model\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Create a DataFrame to store feature importance\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances,'simu' : num_sim })\n",
    "    \n",
    "    # Sort the features based on importance\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def plotFeatureImportance(importance_df,id_sim=100, lsavFig=True):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance' + params['gcv_model'] + '\\n' + params['bestparam'])\n",
    "    #if lsavFig:\n",
    "    plt.savefig(fig_path_run + 'FEAT_IMPF_' + str(id_sim).zfill(4) + '.png')\n",
    "    #else:    \n",
    "    #    plt.show()\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVDT(X_train, y_train,param_grid,scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for DecisionTreeRegressor\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    #param_grid = {\n",
    "    #    'max_depth': [5, 7, 9]    #[3, 4, 5, 7, 9]\n",
    "    #}\n",
    "\n",
    "    # Create the DecisionTreeRegressor model\n",
    "    DT_model = DecisionTreeRegressor()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(DT_model, param_grid, scoring=scorer,verbose=verbose, n_jobs=-1)\n",
    "\n",
    "    if verbose: print('GridSearchCV DecisionTreeRegressor')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    params['gcv_model'] = 'DecisionTreeRegressor'\n",
    "    params['n_test'] = len(grid_search.cv_results_['params'])\n",
    "    params['bestparam'] = str(grid_search.best_params_)\n",
    "    params['bestscore'] = grid_search.best_score_\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    if verbose: print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time'] = elapsed_time\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearchCVXGB(X_train, y_train,param_grid,scorer='neg_mean_absolute_error', verbose=True):\n",
    "    # Grid search CV for XGBoost\n",
    "    # Input :   X_train,y_train : dataframes\n",
    "    #           param_grid dict for GSCV\n",
    "    #           scorer  string : score to use\n",
    "    # Output : GSCV object fitted\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create the  model\n",
    "    XGB_model = xgb.XGBRegressor()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(XGB_model, param_grid, scoring=scorer,verbose=verbose, n_jobs=-1)\n",
    "\n",
    "    if verbose: print('GridSearchCV DecisionTreeRegressor')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    params['gcv_model'] = 'XGBRegressor'\n",
    "    params['n_test'] = len(grid_search.cv_results_['params'])\n",
    "    params['bestparam'] = str(grid_search.best_params_)\n",
    "    params['bestscore'] = grid_search.best_score_\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    if verbose: print(\"Elapsed time: {} minutes {:.2f} seconds\".format(int(minutes), seconds))\n",
    "    params['gcv_time'] = elapsed_time\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "# Define custom MAPE scorer\n",
    "def my_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#m_scorer = make_scorer(my_mean_absolute_percentage_error, greater_is_better=False)\n",
    "m_scorer ='neg_mean_absolute_error'\n",
    "#m_scorer ='neg_root_mean_squared_error'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_result(results_cv_df,params):\n",
    "    # add the content of dict params to result dataframe\n",
    "    new_results_cv = pd.DataFrame(params ,index=[0])\n",
    "    results_cv_df=pd.concat([results_cv_df,new_results_cv],axis=0, ignore_index=True)\n",
    "    return results_cv_df\n",
    "\n",
    "def log_features(df,df_sav):\n",
    "    # add the content of dict features importance to sav dataframe\n",
    "    df_sav = pd.concat([df_sav, df], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise results, the temp reporting dataframe \n",
    "results_cv = pd.DataFrame(columns=['col_sel', 'col_0', 'X_len','score','split','x_trn', 'out_dst','out_abv', 'impute', 'scaler', 'features', 'col_1','RFECVmts','MLsplit','gcv_model', 'n_test', 'bestparam','bestscore', 'gcv_time','SIMU', 'mape', 'mse','r2'])\n",
    "#importance_sav = pd.DataFrame(columns=['Feature','Importance','simu'])\n",
    "errors = pd.DataFrame()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN_ALL_ABOVE to init environment & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute above cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON PARAMS\n",
    "Define ML process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initMLparams(verbose=False):\n",
    "    l_params = {\n",
    "        \"name\": \"config 1\",\n",
    "        \"run_date\": str(datetime.datetime.now()) ,  # use system time\n",
    "        \"selection\": [\"SET1\"],     # Loop 1 : columns selection to use : [\"ALL\", \"SET1\", \"MIN\"]\n",
    "        \"split_method\": [\"None\",\"RANDOM\",\"TIME\"],     # Loop 2 : First spliting method [\"None\", \"RANDOM\", \"TIME\"],\n",
    "        \"split_randomstate\": 458,   \n",
    "        \"split_n\": 7,  # number of split for TimeSeriesSplit\n",
    "        \"remove_outliers_distrib\": True,      # Remove values above a threeshold on distribution for all columns in a dataframe, replace by NaN\n",
    "        \"remove_outliers_distrib_threshold\": 1.5,  # Minimum : (Q1 - threshold * IQR)   Maximum : (Q3 + threshold * IQR)\n",
    "        \"remove_outliers_above\": True,    # Remove values above a threeshold on a columns selection\n",
    "        \"remove_outliers_above_threshold\": 400, # threeshold\n",
    "        \"remove_outliers_above_cols\": [\"inc100\", \"inc100_w1\", \"inc100_w2\"], #  columns selection\n",
    "        \"impute_method\": [ \"TIME\", \"KNN\",\"SIM\"],  # Loop 3 : Inpute method [\"None\", \"TIME\", \"MEAN\", \"MEDIAN\", \"KNN\", \"SIM\", \"ITI\"]\n",
    "        \"impute_nan\": True,\n",
    "        \"impute_zero\": True,\n",
    "        \"scale_method\": \"None\",  #\"None\", \"STD\", \"STD01\", todo, not used\n",
    "        \"select_feature_method\": [\"None\",\"RFECV_GB\"],  # Loop 4 : Feature selection method [\"None\", \"CORR\", \"RFECV_LR\", \"RFECV_GB\"]\n",
    "        \"select_feature_corr\": 0.85,  # treeshold for correlation 0.5 - 0.95\n",
    "        \"select_feature_min\": [4],   #[4, 6, 10]   # Loop 5 : mininum number of features to select\n",
    "        \"select_feature_score\": \"neg_mean_absolute_error\",   # score used\n",
    "        \"select_feature_graph\": True,   # create graph and save as fig\n",
    "        \"select_feature_rfecv_gb\": {                                   \n",
    "            \"loss\": \"absolute_error\",  #  \"ls\", \"absolute_error\",   # param used for GB RFECV\n",
    "            \"n_estimators\": 200,  # 50, 100, 200, 300, 400,\n",
    "            \"max_depth\": 5  # 5, 7, 9, 11, 15\n",
    "        },\n",
    "        \"ml_split_randomstate\": 357,   # Second split\n",
    "        \"ml_split_method\": [\"RANDOM\",\"TIME\"],  # Loop 6 : split method [\"RANDOM\", \"TIME\"]\n",
    "        \"regressors\": [\"DecisionTreeRegressor\",\"XGBRegressor\"],  # Loop 7 : ML regressors list, use None to describe dataset used for fit. \n",
    "                                                                # [\"None\", \"LinearRegression\", \"GradientBoostingRegressor\", \"KNeighborsRegressor\",\"RandomForestRegressor\", \"DecisionTreeRegressor\", \"XGBRegressor\"],\n",
    "        \"regressors_lr\": {                      # GridSearchCV Params grid for LinearRegression\n",
    "            \"fit_intercept\": [True, False]\n",
    "        },\n",
    "        \"regressors_gb\": {                      # GridSearchCV Params grid for GradientBoostingRegressor\n",
    "            \"loss\": [\"absolute_error\"],   #  [\"squared_error\", \"absolute_error\"]\n",
    "            \"n_estimators\": [50,100,200,300],  #[50, 100, 200], \n",
    "            \"max_depth\": [3,5,7,9,11]     #[5, 7, 9]\n",
    "        },\n",
    "        \"regressors_kn\": {                      # GridSearchCV Params grid for KNeighborsRegressor\n",
    "            \"n_neighbors\": [3,5,9],  #[2, 5, 9]\n",
    "            \"algorithm\":  [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]    # [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "        },\n",
    "        \"regressors_rf\": {                      # GridSearchCV Params grid for RandomForestRegressor\n",
    "            \"n_estimators\": [50],   #  [100, 200, 300]\n",
    "            \"max_depth\": [3]    #  [3, 5, 7]\n",
    "        },\n",
    "        \"regressors_dt\": {                      # GridSearchCV Params grid for DecisionTreeRegressor\n",
    "            \"max_depth\": [3, 5, 7]   #[5, 7, 9, 11]\n",
    "        },\n",
    "        \"regressors_xb\": {                      # GridSearchCV Params grid for XGBRegressor\n",
    "            'max_depth':  [3, 5, 7, 9, 11],              # [3, 5, 7, 9, 11],     # Maximum depth of each tree\n",
    "            'learning_rate': [0.1, 0.01, 0.001],         # [0.1, 0.01, 0.001],   # Learning rate\n",
    "            'n_estimators':  [100, 200, 300],    # [100, 200, 300],      # Number of boosting rounds (iterations)\n",
    "            'subsample': [0.8, 1.0],             # [0.8, 1.0],           # Subsample ratio of the training instances\n",
    "            'colsample_bytree': [0.8, 1.0]       # [0.8, 1.0]            # Subsample ratio of columns when constructing each tree\n",
    "        },\n",
    "        \"regressors_score\": \"neg_mean_absolute_error\",     # score used for GSCV : \"neg_mean_absolute_error\",'neg_root_mean_squared_error'  \n",
    "        \"plot_feature_imp\": True,       # bar graph with feature importance\n",
    "        \"plot_reg\": True,               # regression actual/predict graph\n",
    "        \"plot_hist\": True,              # error distribution histogram\n",
    "        \"plot_bar\": True,               # when 'None' regressor used plot distribution\n",
    "        \"plot_feature\":True,            # bar graph for features importances\n",
    "        \"plot_tree\":True                # tree visualisation  for decision trees\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        # Convert to JSON string\n",
    "        json_data = json.dumps(l_params, indent=4)\n",
    "        print(json_data)\n",
    "    return l_params\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from SQL View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Full = pd.read_sql_query('SELECT * FROM v_ari_polu_synop_w1w2;',SQLengine)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "debug = False\n",
    "main_verbose=True\n",
    "barplot=False\n",
    "\n",
    "fig_path=r\"fig/\"\n",
    "fig_path_run = create_directory(fig_path)\n",
    "\n",
    "# Init params auto line, actions and results are auto added to this dict.\n",
    "params= {} \n",
    "importance_df= pd.DataFrame()\n",
    "\n",
    "ml_params = initMLparams(verbose=False)\n",
    "if debug: print('\\n debug mode on')\n",
    "run_count = 0\n",
    "run_total = len(ml_params['selection'])*len(ml_params['split_method'])*len(ml_params['impute_method'])*len(ml_params['select_feature_method'])*len(ml_params['select_feature_min'])\n",
    "#print(run_total)\n",
    "if 'None' in ml_params['select_feature_method']:\n",
    "    run_total = run_total - len(ml_params['select_feature_min']) + 1\n",
    "if 'CORR' in ml_params['select_feature_method']:\n",
    "    run_total = run_total - len(ml_params['select_feature_min'])  + 1 \n",
    "run_total = run_total * len(ml_params['ml_split_method']) * len(ml_params['regressors'])\n",
    "if 'None' in ml_params['regressors']:\n",
    "    run_total = run_total - 1\n",
    "\n",
    "run_total = run_total /2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if main_verbose: print('Starting', run_total, 'runs')\n",
    "if main_verbose: print('Fig dir: ',fig_path_run)\n",
    "#loop1 : column selection\n",
    "for col_select in ml_params['selection']:\n",
    "    \n",
    "    if debug: print('Loop 1, column selection:',col_select)\n",
    "    # X,y creation  columns selection\n",
    "    X,y = FillXy(df_Full,selection=col_select,verbose=debug)  # 'ALL','SET1','MIN'\n",
    "    \n",
    "    params['score']= ml_params['regressors_score']\n",
    "    #loop 2 : split\n",
    "    for split_m in ml_params['split_method']:\n",
    "        \n",
    "        if debug: print('Loop 2, split:',split_m)\n",
    "        X_train, X_test, y_train, y_test= split_data(X, y, split_method=split_m, test_size=0.15, n_splits=5,random_state=ml_params['split_randomstate'],param_name='split' , verbose=debug)\n",
    "    \n",
    "        #removing outlliers\n",
    "        params['out_dst']=False\n",
    "        if ml_params['remove_outliers_distrib']:\n",
    "            if debug: print('Remove outliers distrib:',ml_params['remove_outliers_distrib_threshold'])\n",
    "            X_train = removeOutliers(X_train,cursor=ml_params['remove_outliers_distrib_threshold'], verbose=False)\n",
    "            params['out_dst']=True\n",
    "            \n",
    "        params['out_abv']=False\n",
    "        if ml_params['remove_outliers_above']:\n",
    "            if debug: print('Assign nan_to_values_above_threshold',str(ml_params['remove_outliers_above_cols']))\n",
    "            X_train = assign_nan_to_values_above_threshold(X_train,columns=ml_params['remove_outliers_above_cols'] , threshold=ml_params['remove_outliers_above_threshold'])\n",
    "            params['out_abv']= True\n",
    "\n",
    "        #loop 3 : inpute NaN\n",
    "        for inpute_m in ml_params['impute_method']:\n",
    "            if debug: print('Loop 3, Impute:',inpute_m)\n",
    "            X_train_i = imputeData(X_train,method=inpute_m,l_impute_zeros=ml_params['impute_zero'], l_imputeNaN=ml_params['impute_nan'],l_verbose=debug)\n",
    "            \n",
    "            # scaling\n",
    "            if ml_params['scale_method'] == 'STD':\n",
    "                if debug: print('Scaler:',ml_params['scale_method'])\n",
    "                X_train_i = scaleData(X_train_i,verbose=debug)\n",
    "            \n",
    "            #if debug: describeDataset(X_train,showHead=5,showGraphs=False,showStats=False)\n",
    "            \n",
    "            #loop 4: select_feature_method\n",
    "            for selectfeat_m in ml_params['select_feature_method']:\n",
    "                if debug: print('Loop 4, Select feature method:',selectfeat_m)\n",
    "\n",
    "                #for None and CORR, select_feature_min is ignored, i keep 1 element\n",
    "                min_features=ml_params['select_feature_min']\n",
    "                if selectfeat_m=='None':\n",
    "                    min_features=[0]\n",
    "                    params['features'] ='None'\n",
    "                    params['col_1']=len(X_train_i.columns) \n",
    "                    params['RFECVmts']=0\n",
    "                elif  selectfeat_m=='CORR':\n",
    "                    min_features=[0]\n",
    "\n",
    "\n",
    "                #loop 5: select_feature_min\n",
    "                for minf in min_features:\n",
    "                    #print('minf',minf)\n",
    "                    if debug: print('Loop 5, min feature:',minf)\n",
    "                    X_train_if = selectFeatures(X_train_i,y_train,lparam_grid=ml_params['select_feature_rfecv_gb'],method=selectfeat_m,lseuil=ml_params['select_feature_corr'],lminFeaturesToSelect=minf,lscoRing=ml_params['select_feature_score'],  lgraph=ml_params['select_feature_graph'],num_sim= run_count,lverbose=debug)\n",
    "\n",
    "                    #loop 6: ML split\n",
    "                    for ml_split_m in ml_params['ml_split_method']:\n",
    "                        if debug: print('Loop 6, ML split:',ml_split_m)\n",
    "                        X_train_isp, X_test_isp, y_train_isp, y_test_isp = split_data(X_train_if, y_train, split_method=ml_split_m, test_size=0.15, n_splits=5,random_state=ml_params['ml_split_randomstate'],param_name='MLsplit', verbose=debug)\n",
    "\n",
    "                        # Loop 7 : Regressor\n",
    "                        for regressor in ml_params['regressors']:\n",
    "                            if debug: \n",
    "                                print('Loop 7, Regressor:',regressor)\n",
    "                                print('selected_cols',X_train_isp.columns)\n",
    "                                \n",
    "\n",
    "                            if regressor == 'None':\n",
    "                                describeDataset(X_train_isp,showHead=0,showGraphs=False,showStats=False)\n",
    "\n",
    "                            elif regressor == 'LinearRegression':\n",
    "                                if debug: print('param_grid',ml_params['regressors_lr'])\n",
    "                                GS_model = gridSearchCVLR(X_train_isp,y_train_isp,ml_params['regressors_lr'], scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "                            \n",
    "                            elif regressor == 'GradientBoostingRegressor':\n",
    "                                if debug: print('param_grid',ml_params['regressors_gb'])\n",
    "                                GS_model = gridSearchCVGB(X_train_isp,y_train_isp,ml_params['regressors_gb'],scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "                                \n",
    "                            \n",
    "                            elif regressor == 'KNeighborsRegressor':\n",
    "                                if debug: print('param_grid',ml_params['regressors_kn'])\n",
    "                                GS_model = gridSearchCVKNR(X_train_isp,y_train_isp,ml_params['regressors_kn'],scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "\n",
    "                            elif regressor == 'RandomForestRegressor':\n",
    "                                if debug: print('param_grid',ml_params['regressors_rf'])\n",
    "                                GS_model = gridSearchCVRF(X_train_isp,y_train_isp,ml_params['regressors_rf'],scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "\n",
    "                            elif regressor == 'DecisionTreeRegressor':\n",
    "                                if debug: print('param_grid',ml_params['regressors_dt'])\n",
    "                                GS_model = gridSearchCVDT(X_train_isp,y_train_isp,ml_params['regressors_dt'],scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "\n",
    "                            elif regressor == 'XGBRegressor':\n",
    "                                if debug: print('param_grid',ml_params['regressors_xb'])\n",
    "                                GS_model = gridSearchCVXGB(X_train_isp,y_train_isp,ml_params['regressors_xb'],scorer=ml_params['regressors_score'],verbose=debug)\n",
    "                                barplot=False\n",
    "                            \n",
    "                            if not regressor == 'None': \n",
    "                                run_count += 1\n",
    "                                barplot = barplot and ml_params['plot_bar']\n",
    "                                errors = testModel(GS_model.best_estimator_, X_test=X_test_isp,y_test=y_test_isp, df_errors=errors, regPlot=ml_params['plot_reg'],histplot=ml_params['plot_hist'] ,barPlot=barplot,head_test=True,num_sim=run_count,lsavFig=True, verbose=debug)\n",
    "                                \n",
    "                                if ml_params['plot_feature'] and (regressor in ['GradientBoostingRegressor','RandomForestRegressor','DecisionTreeRegressor','XGBRegressor']):\n",
    "                                    importance_df = getFeatureImportance(GS_model.best_estimator_, X_train_isp.columns,num_sim=run_count)\n",
    "                                    plotFeatureImportance(importance_df,lsavFig=True,id_sim=run_count)\n",
    "\n",
    "                                if regressor in ['DecisionTreeRegressor','XGBRegressor']:\n",
    "                                    #DecisionTreeRegressor\n",
    "                                    viz_model = dtreeviz.model(GS_model.best_estimator_,\n",
    "                                    X_train=X_train_isp, y_train=y_train_isp,\n",
    "                                    feature_names=list(X_train_isp.columns),\n",
    "                                    target_name='inc100',tree_index=0)\n",
    "                                    \n",
    "                                    v = viz_model.view()\n",
    "                                    \n",
    "                                    v.save(fig_path_run + 'TREE_' + str(run_count).zfill(4) + '.svg')\n",
    "                                    viz_model.rtree_feature_space3D(figsize=(8,8),azim=60, elev=20,show='all',features=importance_df['Feature'][:2] )\n",
    "\n",
    "                                if main_verbose: print('Run',run_count, 'done with params:',params)\n",
    "                                results_cv = log_result(results_cv,params)\n",
    "                                importance_sav= log_features(importance_df,importance_sav)\n",
    "if main_verbose: display(results_cv.sort_values('mape',ascending=True))\n",
    "if debug: print('\\n')\n",
    "                \n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_cv.sort_values('mape', ascending=True).head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show biggest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(errors.sort_values(['Error'],ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv.to_excel('results_cv_simu_2k.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_sav.to_excel('Importance_2k.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_excel('errors_2k.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
